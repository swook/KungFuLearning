
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>trainer</title><meta name="generator" content="MATLAB 7.12"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2014-10-13"><meta name="DC.source" content="trainer.m"><style type="text/css">

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head><body><div class="content"><h2>Contents</h2><div><ul><li><a href="#2">Discard insignificant predictors</a></li></ul></div><pre class="codeinput">clear <span class="string">all</span>;

T = importData(<span class="string">'training.csv'</span>);

<span class="comment">% Initial lambda search</span>
lambda = getMinErrLambda(T);
</pre><pre class="codeoutput">     0

     5

    10

    15

    20

    25

    30

    35

    40

    45

    50

    55

    60

    65

    70

    75

    80

    85

    90

    95

   100

     0

    0.2500

    0.5000

    0.7500

     1

    1.2500

    1.5000

    1.7500

     2

    2.2500

    2.5000

    2.7500

     3

    3.2500

    3.5000

    3.7500

     4

    4.2500

    4.5000

    4.7500

     5

     0

    0.0125

    0.0250

    0.0375

    0.0500

    0.0625

    0.0750

    0.0875

    0.1000

    0.1125

    0.1250

    0.1375

    0.1500

    0.1625

    0.1750

    0.1875

    0.2000

    0.2125

    0.2250

    0.2375

    0.2500

     0

   6.2500e-04

    0.0013

    0.0019

    0.0025

    0.0031

    0.0037

    0.0044

    0.0050

    0.0056

    0.0063

    0.0069

    0.0075

    0.0081

    0.0088

    0.0094

    0.0100

    0.0106

    0.0113

    0.0119

    0.0125

     0

   3.1250e-05

   6.2500e-05

   9.3750e-05

   1.2500e-04

   1.5625e-04

   1.8750e-04

   2.1875e-04

   2.5000e-04

   2.8125e-04

   3.1250e-04

   3.4375e-04

   3.7500e-04

   4.0625e-04

   4.3750e-04

   4.6875e-04

   5.0000e-04

   5.3125e-04

   5.6250e-04

   5.9375e-04

   6.2500e-04

     0

   1.5625e-06

   3.1250e-06

   4.6875e-06

   6.2500e-06

   7.8125e-06

   9.3750e-06

   1.0937e-05

   1.2500e-05

   1.4063e-05

   1.5625e-05

   1.7187e-05

   1.8750e-05

   2.0312e-05

   2.1875e-05

   2.3438e-05

   2.5000e-05

   2.6563e-05

   2.8125e-05

   2.9687e-05

   3.1250e-05

     0

   7.8125e-08

   1.5625e-07

   2.3438e-07

   3.1250e-07

   3.9063e-07

   4.6875e-07

   5.4688e-07

   6.2500e-07

   7.0313e-07

   7.8125e-07

   8.5938e-07

   9.3750e-07

   1.0156e-06

   1.0937e-06

   1.1719e-06

   1.2500e-06

   1.3281e-06

   1.4063e-06

   1.4844e-06

   1.5625e-06

</pre><h2>Discard insignificant predictors<a name="2"></a></h2><p>Normalize dataset to be able to identify irrelevant parameters (cols of T)</p><pre class="codeinput">Nrows = size(T, 1);
normT = T(:, 2:end);
normT = (normT - repmat(mean(normT), Nrows, 1)) ./ repmat(var(normT), Nrows, 1);

<span class="comment">% Calculate predictors using preliminary lambda estimate</span>
predictors = ridgeRegression(normT, lambda)

<span class="comment">% Only consider predictors above certain value in ln scale</span>
predictors = log10(abs(predictors))
plot(1:numel(predictors), predictors);
sigcols = find(predictors &gt;  -3.5) + 1; <span class="comment">% First predictor of T is special (and important)</span>
T = T(:, [1; sigcols; size(T, 2)]);

<span class="comment">% Find min err lambda again with reduced dataset</span>
lambda = getMinErrLambda(T);

<span class="comment">% Final predictors</span>
predictors = ridgeRegression(T, lambda);

<span class="comment">% Calculate estimated results from validation set</span>
V = importData(<span class="string">'validation.csv'</span>);

<span class="comment">% Re-insert 0s for insignificant predictors</span>
newpredictors = zeros(size(V, 2), 1);
newpredictors([1; sigcols]) = predictors

<span class="comment">% param_names = [{Width,ROB size,IQ size,LSQ size,RF sizes,RF read ports,...</span>
<span class="comment">%     RF write ports,Gshare size, BTB size, Branches allowed, L1 Icache size,...</span>
<span class="comment">%     L1 Dcache size, L2 Ucache size, Depth}]</span>
<span class="comment">%plot([1:length(newpredictors)-1],(newpredictors(2:end)),'x-')</span>

estR = V * newpredictors;

<span class="comment">% Write our predictions (of time) to file</span>
csvwrite(<span class="string">'predictions.txt'</span>, estR);
</pre><pre class="codeoutput">
predictors =

   -0.0006
   -0.0011
   -0.0001
   -0.0028
    0.0001
   -0.0004
    0.0001
   -0.1788
   -0.0057
    0.0002
   -0.0020
   -0.0192
   -0.0387
    0.0027


predictors =

   -3.2431
   -2.9461
   -4.1545
   -2.5594
   -3.9727
   -3.4039
   -3.9877
   -0.7476
   -2.2427
   -3.6027
   -2.7045
   -1.7177
   -1.4120
   -2.5756

     0

     5

    10

    15

    20

    25

    30

    35

    40

    45

    50

    55

    60

    65

    70

    75

    80

    85

    90

    95

   100

     0

    0.2500

    0.5000

    0.7500

     1

    1.2500

    1.5000

    1.7500

     2

    2.2500

    2.5000

    2.7500

     3

    3.2500

    3.5000

    3.7500

     4

    4.2500

    4.5000

    4.7500

     5

     0

    0.0125

    0.0250

    0.0375

    0.0500

    0.0625

    0.0750

    0.0875

    0.1000

    0.1125

    0.1250

    0.1375

    0.1500

    0.1625

    0.1750

    0.1875

    0.2000

    0.2125

    0.2250

    0.2375

    0.2500

     0

   6.2500e-04

    0.0013

    0.0019

    0.0025

    0.0031

    0.0037

    0.0044

    0.0050

    0.0056

    0.0063

    0.0069

    0.0075

    0.0081

    0.0088

    0.0094

    0.0100

    0.0106

    0.0113

    0.0119

    0.0125

     0

   3.1250e-05

   6.2500e-05

   9.3750e-05

   1.2500e-04

   1.5625e-04

   1.8750e-04

   2.1875e-04

   2.5000e-04

   2.8125e-04

   3.1250e-04

   3.4375e-04

   3.7500e-04

   4.0625e-04

   4.3750e-04

   4.6875e-04

   5.0000e-04

   5.3125e-04

   5.6250e-04

   5.9375e-04

   6.2500e-04

     0

   1.5625e-06

   3.1250e-06

   4.6875e-06

   6.2500e-06

   7.8125e-06

   9.3750e-06

   1.0937e-05

   1.2500e-05

   1.4063e-05

   1.5625e-05

   1.7187e-05

   1.8750e-05

   2.0312e-05

   2.1875e-05

   2.3438e-05

   2.5000e-05

   2.6563e-05

   2.8125e-05

   2.9687e-05

   3.1250e-05

     0

   7.8125e-08

   1.5625e-07

   2.3438e-07

   3.1250e-07

   3.9063e-07

   4.6875e-07

   5.4688e-07

   6.2500e-07

   7.0313e-07

   7.8125e-07

   8.5938e-07

   9.3750e-07

   1.0156e-06

   1.0937e-06

   1.1719e-06

   1.2500e-06

   1.3281e-06

   1.4063e-06

   1.4844e-06

   1.5625e-06


newpredictors =

   1.0e+03 *

    5.1665
   -0.4182
   -0.0023
         0
   -0.0108
         0
   -0.0475
         0
   -0.0000
   -0.0001
         0
   -0.0000
   -0.0003
   -0.0000
    0.0783

</pre><p class="footer"><br>
      Published with MATLAB&reg; 7.12<br></p></div><!--
##### SOURCE BEGIN #####
clear all;

T = importData('training.csv');

% Initial lambda search
lambda = getMinErrLambda(T);

%% Discard insignificant predictors
% Normalize dataset to be able to identify irrelevant parameters (cols of T)
Nrows = size(T, 1);
normT = T(:, 2:end);
normT = (normT - repmat(mean(normT), Nrows, 1)) ./ repmat(var(normT), Nrows, 1);

% Calculate predictors using preliminary lambda estimate
predictors = ridgeRegression(normT, lambda)

% Only consider predictors above certain value in ln scale
predictors = log10(abs(predictors))
plot(1:numel(predictors), predictors);
sigcols = find(predictors >  -3.5) + 1; % First predictor of T is special (and important)
T = T(:, [1; sigcols; size(T, 2)]);

% Find min err lambda again with reduced dataset
lambda = getMinErrLambda(T);

% Final predictors
predictors = ridgeRegression(T, lambda);

% Calculate estimated results from validation set
V = importData('validation.csv');

% Re-insert 0s for insignificant predictors
newpredictors = zeros(size(V, 2), 1);
newpredictors([1; sigcols]) = predictors

% param_names = [{Width,ROB size,IQ size,LSQ size,RF sizes,RF read ports,...
%     RF write ports,Gshare size, BTB size, Branches allowed, L1 Icache size,...
%     L1 Dcache size, L2 Ucache size, Depth}]
%plot([1:length(newpredictors)-1],(newpredictors(2:end)),'x-')

estR = V * newpredictors;

% Write our predictions (of time) to file
csvwrite('predictions.txt', estR);


##### SOURCE END #####
--></body></html>